Args in experiment:
Namespace(is_training=1, model_id='ETTm2_96_192', model='Transformer', data='ETTm2', root_path='./dataset/', data_path='ETTm2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=192, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=5, use_multi_gpu=False, devices='0,1,2,3', test_flop=True)
Use GPU: cuda:5
>>>>>>>start training : ETTm2_96_192_Transformer_ETTm2_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34273
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.3060617
	speed: 0.1012s/iter; left time: 1073.5787s
	iters: 200, epoch: 1 | loss: 0.2471078
	speed: 0.0368s/iter; left time: 386.3753s
	iters: 300, epoch: 1 | loss: 0.2776861
	speed: 0.0373s/iter; left time: 388.6193s
	iters: 400, epoch: 1 | loss: 0.1937656
	speed: 0.0371s/iter; left time: 382.5456s
	iters: 500, epoch: 1 | loss: 0.2337213
	speed: 0.0373s/iter; left time: 380.7671s
	iters: 600, epoch: 1 | loss: 0.2363219
	speed: 0.0385s/iter; left time: 389.3259s
	iters: 700, epoch: 1 | loss: 0.1347034
	speed: 0.0377s/iter; left time: 377.0814s
	iters: 800, epoch: 1 | loss: 0.1566754
	speed: 0.0382s/iter; left time: 378.2483s
	iters: 900, epoch: 1 | loss: 0.1821286
	speed: 0.0383s/iter; left time: 376.0154s
	iters: 1000, epoch: 1 | loss: 0.1272336
	speed: 0.0375s/iter; left time: 363.9200s
Epoch: 1 cost time: 46.68994617462158
Epoch: 1, Steps: 1071 | Train Loss: 0.2059967 Vali Loss: 0.4677722 Test Loss: 1.1928669
Validation loss decreased (inf --> 0.467772).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.1224201
	speed: 0.2185s/iter; left time: 2084.3983s
	iters: 200, epoch: 2 | loss: 0.1406373
	speed: 0.0394s/iter; left time: 371.8755s
	iters: 300, epoch: 2 | loss: 0.1412456
	speed: 0.0375s/iter; left time: 350.3924s
	iters: 400, epoch: 2 | loss: 0.0951402
	speed: 0.0382s/iter; left time: 352.7438s
	iters: 500, epoch: 2 | loss: 0.1149666
	speed: 0.0377s/iter; left time: 344.8054s
	iters: 600, epoch: 2 | loss: 0.1099126
	speed: 0.0371s/iter; left time: 335.1459s
	iters: 700, epoch: 2 | loss: 0.1096245
	speed: 0.0368s/iter; left time: 329.4228s
	iters: 800, epoch: 2 | loss: 0.0854009
	speed: 0.0385s/iter; left time: 340.1340s
	iters: 900, epoch: 2 | loss: 0.1166434
	speed: 0.0381s/iter; left time: 332.8992s
	iters: 1000, epoch: 2 | loss: 0.1169641
	speed: 0.0374s/iter; left time: 323.4947s
Epoch: 2 cost time: 42.16619110107422
Epoch: 2, Steps: 1071 | Train Loss: 0.1178905 Vali Loss: 0.5971925 Test Loss: 1.1673286
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.1014179
	speed: 0.2168s/iter; left time: 1835.8082s
	iters: 200, epoch: 3 | loss: 0.0856236
	speed: 0.0384s/iter; left time: 321.0224s
	iters: 300, epoch: 3 | loss: 0.0895848
	speed: 0.0372s/iter; left time: 307.8811s
	iters: 400, epoch: 3 | loss: 0.0674667
	speed: 0.0384s/iter; left time: 313.3720s
	iters: 500, epoch: 3 | loss: 0.0850349
	speed: 0.0372s/iter; left time: 300.4611s
	iters: 600, epoch: 3 | loss: 0.0774985
	speed: 0.0369s/iter; left time: 294.2491s
	iters: 700, epoch: 3 | loss: 0.0862286
	speed: 0.0373s/iter; left time: 293.4810s
	iters: 800, epoch: 3 | loss: 0.0878616
	speed: 0.0377s/iter; left time: 292.9952s
	iters: 900, epoch: 3 | loss: 0.0774987
	speed: 0.0371s/iter; left time: 284.7920s
	iters: 1000, epoch: 3 | loss: 0.0806035
	speed: 0.0367s/iter; left time: 278.1465s
Epoch: 3 cost time: 41.9124059677124
Epoch: 3, Steps: 1071 | Train Loss: 0.0826578 Vali Loss: 0.6496960 Test Loss: 1.2004192
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.0689933
	speed: 0.2174s/iter; left time: 1608.4704s
	iters: 200, epoch: 4 | loss: 0.0663822
	speed: 0.0371s/iter; left time: 270.4390s
	iters: 300, epoch: 4 | loss: 0.0802106
	speed: 0.0395s/iter; left time: 284.1904s
	iters: 400, epoch: 4 | loss: 0.0780282
	speed: 0.0370s/iter; left time: 262.4681s
	iters: 500, epoch: 4 | loss: 0.0703242
	speed: 0.0370s/iter; left time: 258.8631s
	iters: 600, epoch: 4 | loss: 0.0661620
	speed: 0.0375s/iter; left time: 258.9524s
	iters: 700, epoch: 4 | loss: 0.0715088
	speed: 0.0366s/iter; left time: 248.7706s
	iters: 800, epoch: 4 | loss: 0.0657008
	speed: 0.0375s/iter; left time: 251.0888s
	iters: 900, epoch: 4 | loss: 0.0772341
	speed: 0.0374s/iter; left time: 246.7517s
	iters: 1000, epoch: 4 | loss: 0.0722587
	speed: 0.0370s/iter; left time: 240.7364s
Epoch: 4 cost time: 41.75537872314453
Epoch: 4, Steps: 1071 | Train Loss: 0.0698101 Vali Loss: 0.6366832 Test Loss: 1.1021986
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm2_96_192_Transformer_ETTm2_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
mse:1.1928672790527344, mae:0.8000358939170837
INFO: Trainable parameter count: 0.01M
INFO: Trainable parameter count: 0.01M
INFO: Trainable parameter count: 0.02M
INFO: Trainable parameter count: 0.03M
INFO: Trainable parameter count: 0.29M
INFO: Trainable parameter count: 0.29M
INFO: Trainable parameter count: 0.55M
INFO: Trainable parameter count: 0.55M
INFO: Trainable parameter count: 0.81M
INFO: Trainable parameter count: 0.81M
INFO: Trainable parameter count: 1.08M
INFO: Trainable parameter count: 1.08M
INFO: Trainable parameter count: 2.12M
INFO: Trainable parameter count: 2.13M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.44M
INFO: Trainable parameter count: 3.44M
INFO: Trainable parameter count: 3.70M
INFO: Trainable parameter count: 3.70M
INFO: Trainable parameter count: 3.97M
INFO: Trainable parameter count: 3.97M
INFO: Trainable parameter count: 4.23M
INFO: Trainable parameter count: 4.23M
INFO: Trainable parameter count: 5.28M
INFO: Trainable parameter count: 5.28M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 6.59M
INFO: Trainable parameter count: 6.59M
INFO: Trainable parameter count: 6.86M
INFO: Trainable parameter count: 6.86M
INFO: Trainable parameter count: 7.12M
INFO: Trainable parameter count: 7.12M
INFO: Trainable parameter count: 7.38M
INFO: Trainable parameter count: 7.38M
INFO: Trainable parameter count: 7.64M
INFO: Trainable parameter count: 7.64M
INFO: Trainable parameter count: 7.91M
INFO: Trainable parameter count: 7.91M
INFO: Trainable parameter count: 8.17M
INFO: Trainable parameter count: 8.17M
INFO: Trainable parameter count: 8.43M
INFO: Trainable parameter count: 8.43M
INFO: Trainable parameter count: 9.48M
INFO: Trainable parameter count: 9.48M
INFO: Trainable parameter count: 10.53M
INFO: Trainable parameter count: 10.53M
INFO: Trainable parameter count: 10.53M
INFO: Trainable parameter count: 10.53M
INFO: Trainable parameter count: 10.53M
INFO: Trainable parameter count: 10.53M
INFO: Trainable parameter count: 10.53M
INFO: Trainable parameter count: 10.54M
INFO: Trainable parameter count: 10.54M
INFO: Trainable parameter count: 10.54M
INFO: Trainable parameter count: 10.54M
INFO: Trainable parameter count: 10.54M
