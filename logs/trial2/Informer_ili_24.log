Args in experiment:
Namespace(is_training=1, model_id='ili_36_24', model='Informer', data='custom', root_path='./dataset/', data_path='national_illness.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=36, label_len=18, pred_len=24, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=7, use_multi_gpu=False, devices='0,1,2,3', test_flop=True)
Use GPU: cuda:7
>>>>>>>start training : ili_36_24_Informer_custom_ftM_sl36_ll18_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 617
val 74
test 170
Epoch: 1 cost time: 8.153527021408081
Epoch: 1, Steps: 19 | Train Loss: 0.7832142 Vali Loss: 0.3926463 Test Loss: 4.8668122
Validation loss decreased (inf --> 0.392646).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 2.1624722480773926
Epoch: 2, Steps: 19 | Train Loss: 0.4602609 Vali Loss: 0.3098792 Test Loss: 5.4986963
Validation loss decreased (0.392646 --> 0.309879).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 2.259648561477661
Epoch: 3, Steps: 19 | Train Loss: 0.3720471 Vali Loss: 0.2783934 Test Loss: 5.2596374
Validation loss decreased (0.309879 --> 0.278393).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 2.467907428741455
Epoch: 4, Steps: 19 | Train Loss: 0.3340710 Vali Loss: 0.3203042 Test Loss: 4.9873857
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 2.3596410751342773
Epoch: 5, Steps: 19 | Train Loss: 0.3174652 Vali Loss: 0.2739001 Test Loss: 5.3530512
Validation loss decreased (0.278393 --> 0.273900).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 2.447826862335205
Epoch: 6, Steps: 19 | Train Loss: 0.3179744 Vali Loss: 0.2615063 Test Loss: 5.3005667
Validation loss decreased (0.273900 --> 0.261506).  Saving model ...
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 2.1116747856140137
Epoch: 7, Steps: 19 | Train Loss: 0.3093325 Vali Loss: 0.2637470 Test Loss: 5.3052769
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 2.330439329147339
Epoch: 8, Steps: 19 | Train Loss: 0.3026955 Vali Loss: 0.2473379 Test Loss: 5.2826457
Validation loss decreased (0.261506 --> 0.247338).  Saving model ...
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 2.512174606323242
Epoch: 9, Steps: 19 | Train Loss: 0.3008960 Vali Loss: 0.2499543 Test Loss: 5.2997017
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 2.286470890045166
Epoch: 10, Steps: 19 | Train Loss: 0.3030985 Vali Loss: 0.2753910 Test Loss: 5.2781878
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.953125e-07
>>>>>>>testing : ili_36_24_Informer_custom_ftM_sl36_ll18_pl24_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 170
mse:5.283447265625, mae:1.5831778049468994
INFO: Trainable parameter count: 0.01M
INFO: Trainable parameter count: 0.01M
INFO: Trainable parameter count: 0.02M
INFO: Trainable parameter count: 0.03M
INFO: Trainable parameter count: 0.29M
INFO: Trainable parameter count: 0.29M
INFO: Trainable parameter count: 0.55M
INFO: Trainable parameter count: 0.55M
INFO: Trainable parameter count: 0.81M
INFO: Trainable parameter count: 0.81M
INFO: Trainable parameter count: 1.08M
INFO: Trainable parameter count: 1.08M
INFO: Trainable parameter count: 2.12M
INFO: Trainable parameter count: 2.13M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.44M
INFO: Trainable parameter count: 3.44M
INFO: Trainable parameter count: 3.70M
INFO: Trainable parameter count: 3.70M
INFO: Trainable parameter count: 3.97M
INFO: Trainable parameter count: 3.97M
INFO: Trainable parameter count: 4.23M
INFO: Trainable parameter count: 4.23M
INFO: Trainable parameter count: 5.28M
INFO: Trainable parameter count: 5.28M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 7.12M
INFO: Trainable parameter count: 7.12M
INFO: Trainable parameter count: 7.12M
INFO: Trainable parameter count: 7.12M
INFO: Trainable parameter count: 7.12M
INFO: Trainable parameter count: 7.12M
INFO: Trainable parameter count: 7.38M
INFO: Trainable parameter count: 7.38M
INFO: Trainable parameter count: 7.64M
INFO: Trainable parameter count: 7.64M
INFO: Trainable parameter count: 7.91M
INFO: Trainable parameter count: 7.91M
INFO: Trainable parameter count: 8.17M
INFO: Trainable parameter count: 8.17M
INFO: Trainable parameter count: 8.43M
INFO: Trainable parameter count: 8.43M
INFO: Trainable parameter count: 8.69M
INFO: Trainable parameter count: 8.70M
INFO: Trainable parameter count: 8.96M
INFO: Trainable parameter count: 8.96M
INFO: Trainable parameter count: 9.22M
INFO: Trainable parameter count: 9.22M
INFO: Trainable parameter count: 10.27M
INFO: Trainable parameter count: 10.27M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.33M
INFO: Trainable parameter count: 11.33M
