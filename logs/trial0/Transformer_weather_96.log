Args in experiment:
Namespace(is_training=1, model_id='weather_96_96', model='Transformer', data='custom', root_path='./dataset/', data_path='weather.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, individual=False, embed_type=0, enc_in=21, dec_in=21, c_out=21, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=2, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=9, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:9
>>>>>>>start training : weather_96_96_Transformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 36696
val 5175
test 10444
	iters: 100, epoch: 1 | loss: 0.4803032
	speed: 0.1037s/iter; left time: 227.3295s
	iters: 200, epoch: 1 | loss: 0.2575134
	speed: 0.0341s/iter; left time: 71.4057s
	iters: 300, epoch: 1 | loss: 0.3911276
	speed: 0.0347s/iter; left time: 69.1240s
	iters: 400, epoch: 1 | loss: 0.1731965
	speed: 0.0339s/iter; left time: 64.2136s
	iters: 500, epoch: 1 | loss: 0.2057086
	speed: 0.0366s/iter; left time: 65.6399s
	iters: 600, epoch: 1 | loss: 0.2008575
	speed: 0.0344s/iter; left time: 58.2188s
	iters: 700, epoch: 1 | loss: 0.2026478
	speed: 0.0338s/iter; left time: 53.8560s
	iters: 800, epoch: 1 | loss: 1.1051044
	speed: 0.0355s/iter; left time: 52.9877s
	iters: 900, epoch: 1 | loss: 0.3218537
	speed: 0.0359s/iter; left time: 50.0495s
	iters: 1000, epoch: 1 | loss: 0.1768925
	speed: 0.0336s/iter; left time: 43.3908s
	iters: 1100, epoch: 1 | loss: 0.1429760
	speed: 0.0341s/iter; left time: 40.6761s
Epoch: 1 cost time: 46.66953682899475
Epoch: 1, Steps: 1146 | Train Loss: 0.3563341 Vali Loss: 0.5136563 Test Loss: 0.3685430
Validation loss decreased (inf --> 0.513656).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.1557539
	speed: 0.1640s/iter; left time: 171.7070s
	iters: 200, epoch: 2 | loss: 0.1529270
	speed: 0.0350s/iter; left time: 33.1229s
	iters: 300, epoch: 2 | loss: 0.3315486
	speed: 0.0352s/iter; left time: 29.8176s
	iters: 400, epoch: 2 | loss: 0.1662022
	speed: 0.0360s/iter; left time: 26.9245s
	iters: 500, epoch: 2 | loss: 0.7641581
	speed: 0.0367s/iter; left time: 23.7643s
	iters: 600, epoch: 2 | loss: 0.1269804
	speed: 0.0344s/iter; left time: 18.7970s
	iters: 700, epoch: 2 | loss: 0.2044831
	speed: 0.0355s/iter; left time: 15.8682s
	iters: 800, epoch: 2 | loss: 0.1114284
	speed: 0.0373s/iter; left time: 12.9387s
	iters: 900, epoch: 2 | loss: 0.1413316
	speed: 0.0379s/iter; left time: 9.3709s
	iters: 1000, epoch: 2 | loss: 0.1686259
	speed: 0.0375s/iter; left time: 5.5085s
	iters: 1100, epoch: 2 | loss: 0.1425152
	speed: 0.0365s/iter; left time: 1.7165s
Epoch: 2 cost time: 42.60914587974548
Epoch: 2, Steps: 1146 | Train Loss: 0.2575856 Vali Loss: 0.5102168 Test Loss: 0.4235051
Validation loss decreased (0.513656 --> 0.510217).  Saving model ...
Updating learning rate to 5e-05
>>>>>>>testing : weather_96_96_Transformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
mse:0.4235048294067383, mae:0.4449614882469177
