Args in experiment:
Namespace(is_training=1, model_id='ETTm2_96_336', model='Informer', data='ETTm2', root_path='./dataset/', data_path='ETTm2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=336, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=5, use_multi_gpu=False, devices='0,1,2,3', test_flop=True)
Use GPU: cuda:5
>>>>>>>start training : ETTm2_96_336_Informer_ETTm2_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.3943452
	speed: 0.1176s/iter; left time: 1242.0713s
	iters: 200, epoch: 1 | loss: 0.3266704
	speed: 0.0630s/iter; left time: 658.6672s
	iters: 300, epoch: 1 | loss: 0.1984361
	speed: 0.0627s/iter; left time: 649.1998s
	iters: 400, epoch: 1 | loss: 0.3555627
	speed: 0.0647s/iter; left time: 663.6035s
	iters: 500, epoch: 1 | loss: 0.2856671
	speed: 0.0627s/iter; left time: 637.3595s
	iters: 600, epoch: 1 | loss: 0.3334508
	speed: 0.0627s/iter; left time: 630.9119s
	iters: 700, epoch: 1 | loss: 0.2665463
	speed: 0.0657s/iter; left time: 654.2874s
	iters: 800, epoch: 1 | loss: 0.2149008
	speed: 0.0644s/iter; left time: 634.8790s
	iters: 900, epoch: 1 | loss: 0.2352738
	speed: 0.0634s/iter; left time: 618.3722s
	iters: 1000, epoch: 1 | loss: 0.2100025
	speed: 0.0636s/iter; left time: 614.3162s
Epoch: 1 cost time: 73.38506388664246
Epoch: 1, Steps: 1066 | Train Loss: 0.2864379 Vali Loss: 0.5928647 Test Loss: 1.4324815
Validation loss decreased (inf --> 0.592865).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2286856
	speed: 0.3148s/iter; left time: 2989.1341s
	iters: 200, epoch: 2 | loss: 0.2169818
	speed: 0.0638s/iter; left time: 599.4676s
	iters: 300, epoch: 2 | loss: 0.1695095
	speed: 0.0639s/iter; left time: 593.9484s
	iters: 400, epoch: 2 | loss: 0.1786308
	speed: 0.0637s/iter; left time: 585.7358s
	iters: 500, epoch: 2 | loss: 0.1738888
	speed: 0.0630s/iter; left time: 572.8982s
	iters: 600, epoch: 2 | loss: 0.1763391
	speed: 0.0636s/iter; left time: 572.3323s
	iters: 700, epoch: 2 | loss: 0.1941780
	speed: 0.0641s/iter; left time: 569.9310s
	iters: 800, epoch: 2 | loss: 0.1803772
	speed: 0.0626s/iter; left time: 550.9278s
	iters: 900, epoch: 2 | loss: 0.1643868
	speed: 0.0652s/iter; left time: 566.5399s
	iters: 1000, epoch: 2 | loss: 0.1698536
	speed: 0.0648s/iter; left time: 556.9550s
Epoch: 2 cost time: 69.82900547981262
Epoch: 2, Steps: 1066 | Train Loss: 0.1988373 Vali Loss: 0.6466262 Test Loss: 1.4056420
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.1629386
	speed: 0.3095s/iter; left time: 2608.9611s
	iters: 200, epoch: 3 | loss: 0.1694239
	speed: 0.0638s/iter; left time: 531.2099s
	iters: 300, epoch: 3 | loss: 0.1357794
	speed: 0.0642s/iter; left time: 528.6054s
	iters: 400, epoch: 3 | loss: 0.1515679
	speed: 0.0643s/iter; left time: 523.0578s
	iters: 500, epoch: 3 | loss: 0.1476481
	speed: 0.0643s/iter; left time: 516.5030s
	iters: 600, epoch: 3 | loss: 0.1272053
	speed: 0.0631s/iter; left time: 500.6813s
	iters: 700, epoch: 3 | loss: 0.1279394
	speed: 0.0638s/iter; left time: 499.8799s
	iters: 800, epoch: 3 | loss: 0.1169837
	speed: 0.0634s/iter; left time: 490.2192s
	iters: 900, epoch: 3 | loss: 0.1527967
	speed: 0.0666s/iter; left time: 508.1382s
	iters: 1000, epoch: 3 | loss: 0.1637686
	speed: 0.0656s/iter; left time: 494.2674s
Epoch: 3 cost time: 70.26720356941223
Epoch: 3, Steps: 1066 | Train Loss: 0.1506524 Vali Loss: 0.7696097 Test Loss: 1.8056581
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.1270143
	speed: 0.3418s/iter; left time: 2516.8793s
	iters: 200, epoch: 4 | loss: 0.1631670
	speed: 0.0668s/iter; left time: 485.3021s
	iters: 300, epoch: 4 | loss: 0.1057617
	speed: 0.0675s/iter; left time: 483.5875s
	iters: 400, epoch: 4 | loss: 0.1365521
	speed: 0.0669s/iter; left time: 472.2073s
	iters: 500, epoch: 4 | loss: 0.1175357
	speed: 0.0673s/iter; left time: 468.6606s
	iters: 600, epoch: 4 | loss: 0.1063085
	speed: 0.0683s/iter; left time: 468.4422s
	iters: 700, epoch: 4 | loss: 0.1333817
	speed: 0.0672s/iter; left time: 454.4212s
	iters: 800, epoch: 4 | loss: 0.1046198
	speed: 0.0664s/iter; left time: 442.1893s
	iters: 900, epoch: 4 | loss: 0.1502661
	speed: 0.0676s/iter; left time: 443.9736s
	iters: 1000, epoch: 4 | loss: 0.1107412
	speed: 0.0679s/iter; left time: 438.5147s
Epoch: 4 cost time: 73.90309619903564
Epoch: 4, Steps: 1066 | Train Loss: 0.1268304 Vali Loss: 0.8120791 Test Loss: 1.9045061
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm2_96_336_Informer_ETTm2_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:1.4325708150863647, mae:0.9187150001525879
INFO: Trainable parameter count: 0.01M
INFO: Trainable parameter count: 0.01M
INFO: Trainable parameter count: 0.02M
INFO: Trainable parameter count: 0.03M
INFO: Trainable parameter count: 0.29M
INFO: Trainable parameter count: 0.29M
INFO: Trainable parameter count: 0.55M
INFO: Trainable parameter count: 0.55M
INFO: Trainable parameter count: 0.81M
INFO: Trainable parameter count: 0.81M
INFO: Trainable parameter count: 1.08M
INFO: Trainable parameter count: 1.08M
INFO: Trainable parameter count: 2.12M
INFO: Trainable parameter count: 2.13M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.44M
INFO: Trainable parameter count: 3.44M
INFO: Trainable parameter count: 3.70M
INFO: Trainable parameter count: 3.70M
INFO: Trainable parameter count: 3.97M
INFO: Trainable parameter count: 3.97M
INFO: Trainable parameter count: 4.23M
INFO: Trainable parameter count: 4.23M
INFO: Trainable parameter count: 5.28M
INFO: Trainable parameter count: 5.28M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 7.12M
INFO: Trainable parameter count: 7.12M
INFO: Trainable parameter count: 7.12M
INFO: Trainable parameter count: 7.12M
INFO: Trainable parameter count: 7.12M
INFO: Trainable parameter count: 7.12M
INFO: Trainable parameter count: 7.38M
INFO: Trainable parameter count: 7.38M
INFO: Trainable parameter count: 7.64M
INFO: Trainable parameter count: 7.64M
INFO: Trainable parameter count: 7.91M
INFO: Trainable parameter count: 7.91M
INFO: Trainable parameter count: 8.17M
INFO: Trainable parameter count: 8.17M
INFO: Trainable parameter count: 8.43M
INFO: Trainable parameter count: 8.43M
INFO: Trainable parameter count: 8.69M
INFO: Trainable parameter count: 8.70M
INFO: Trainable parameter count: 8.96M
INFO: Trainable parameter count: 8.96M
INFO: Trainable parameter count: 9.22M
INFO: Trainable parameter count: 9.22M
INFO: Trainable parameter count: 10.27M
INFO: Trainable parameter count: 10.27M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.33M
INFO: Trainable parameter count: 11.33M
