Args in experiment:
Namespace(is_training=1, model_id='ETTm1_96_336', model='Informer', data='ETTm1', root_path='./dataset/', data_path='ETTm1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=336, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=4, use_multi_gpu=False, devices='0,1,2,3', test_flop=True)
Use GPU: cuda:4
>>>>>>>start training : ETTm1_96_336_Informer_ETTm1_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.4479170
	speed: 0.1185s/iter; left time: 1251.6880s
	iters: 200, epoch: 1 | loss: 0.4852581
	speed: 0.0632s/iter; left time: 660.9310s
	iters: 300, epoch: 1 | loss: 0.5236242
	speed: 0.0632s/iter; left time: 654.6587s
	iters: 400, epoch: 1 | loss: 0.4044938
	speed: 0.0637s/iter; left time: 653.7737s
	iters: 500, epoch: 1 | loss: 0.3807158
	speed: 0.0638s/iter; left time: 648.0279s
	iters: 600, epoch: 1 | loss: 0.3785901
	speed: 0.0636s/iter; left time: 639.7804s
	iters: 700, epoch: 1 | loss: 0.3624699
	speed: 0.0638s/iter; left time: 635.4693s
	iters: 800, epoch: 1 | loss: 0.3533937
	speed: 0.0632s/iter; left time: 622.8808s
	iters: 900, epoch: 1 | loss: 0.3315120
	speed: 0.0630s/iter; left time: 614.6997s
	iters: 1000, epoch: 1 | loss: 0.3048562
	speed: 0.0633s/iter; left time: 611.1125s
Epoch: 1 cost time: 73.3626127243042
Epoch: 1, Steps: 1066 | Train Loss: 0.3938665 Vali Loss: 1.0807120 Test Loss: 1.2639737
Validation loss decreased (inf --> 1.080712).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2882636
	speed: 0.3098s/iter; left time: 2941.4158s
	iters: 200, epoch: 2 | loss: 0.3240408
	speed: 0.0646s/iter; left time: 606.6567s
	iters: 300, epoch: 2 | loss: 0.2737305
	speed: 0.0630s/iter; left time: 585.8191s
	iters: 400, epoch: 2 | loss: 0.2728098
	speed: 0.0630s/iter; left time: 579.2582s
	iters: 500, epoch: 2 | loss: 0.2581666
	speed: 0.0628s/iter; left time: 571.4067s
	iters: 600, epoch: 2 | loss: 0.2760294
	speed: 0.0639s/iter; left time: 574.9757s
	iters: 700, epoch: 2 | loss: 0.2629405
	speed: 0.0629s/iter; left time: 559.1451s
	iters: 800, epoch: 2 | loss: 0.2443572
	speed: 0.0628s/iter; left time: 551.9766s
	iters: 900, epoch: 2 | loss: 0.2291694
	speed: 0.0629s/iter; left time: 547.2262s
	iters: 1000, epoch: 2 | loss: 0.2577486
	speed: 0.0625s/iter; left time: 536.8953s
Epoch: 2 cost time: 68.86958122253418
Epoch: 2, Steps: 1066 | Train Loss: 0.2730200 Vali Loss: 1.0323749 Test Loss: 1.0589913
Validation loss decreased (1.080712 --> 1.032375).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.2651695
	speed: 0.3127s/iter; left time: 2635.5459s
	iters: 200, epoch: 3 | loss: 0.2287355
	speed: 0.0625s/iter; left time: 520.2149s
	iters: 300, epoch: 3 | loss: 0.2185476
	speed: 0.0624s/iter; left time: 513.2450s
	iters: 400, epoch: 3 | loss: 0.2213022
	speed: 0.0638s/iter; left time: 518.8911s
	iters: 500, epoch: 3 | loss: 0.2264890
	speed: 0.0629s/iter; left time: 504.8300s
	iters: 600, epoch: 3 | loss: 0.2256830
	speed: 0.0638s/iter; left time: 506.0176s
	iters: 700, epoch: 3 | loss: 0.2049550
	speed: 0.0637s/iter; left time: 498.8278s
	iters: 800, epoch: 3 | loss: 0.2082636
	speed: 0.0627s/iter; left time: 484.5586s
	iters: 900, epoch: 3 | loss: 0.1979857
	speed: 0.0639s/iter; left time: 487.8621s
	iters: 1000, epoch: 3 | loss: 0.2095881
	speed: 0.0613s/iter; left time: 461.4431s
Epoch: 3 cost time: 68.70838618278503
Epoch: 3, Steps: 1066 | Train Loss: 0.2157257 Vali Loss: 1.1413926 Test Loss: 1.1866881
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.1915457
	speed: 0.3289s/iter; left time: 2422.0273s
	iters: 200, epoch: 4 | loss: 0.1941041
	speed: 0.0692s/iter; left time: 502.2854s
	iters: 300, epoch: 4 | loss: 0.1926152
	speed: 0.0693s/iter; left time: 496.1490s
	iters: 400, epoch: 4 | loss: 0.1814551
	speed: 0.0668s/iter; left time: 471.7970s
	iters: 500, epoch: 4 | loss: 0.1774052
	speed: 0.0659s/iter; left time: 458.8658s
	iters: 600, epoch: 4 | loss: 0.2085392
	speed: 0.0668s/iter; left time: 458.3018s
	iters: 700, epoch: 4 | loss: 0.1893630
	speed: 0.0673s/iter; left time: 454.8148s
	iters: 800, epoch: 4 | loss: 0.1687082
	speed: 0.0673s/iter; left time: 448.5730s
	iters: 900, epoch: 4 | loss: 0.1939262
	speed: 0.0663s/iter; left time: 435.2945s
	iters: 1000, epoch: 4 | loss: 0.1889993
	speed: 0.0672s/iter; left time: 434.4842s
Epoch: 4 cost time: 73.61021184921265
Epoch: 4, Steps: 1066 | Train Loss: 0.1879214 Vali Loss: 1.1211209 Test Loss: 1.1420720
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.1768780
	speed: 0.3332s/iter; left time: 2097.9445s
	iters: 200, epoch: 5 | loss: 0.1754822
	speed: 0.0674s/iter; left time: 417.8912s
	iters: 300, epoch: 5 | loss: 0.1714780
	speed: 0.0654s/iter; left time: 398.8199s
	iters: 400, epoch: 5 | loss: 0.1788961
	speed: 0.0662s/iter; left time: 396.8887s
	iters: 500, epoch: 5 | loss: 0.1751413
	speed: 0.0666s/iter; left time: 392.6899s
	iters: 600, epoch: 5 | loss: 0.1767830
	speed: 0.0668s/iter; left time: 387.2044s
	iters: 700, epoch: 5 | loss: 0.1648672
	speed: 0.0667s/iter; left time: 380.0656s
	iters: 800, epoch: 5 | loss: 0.1857286
	speed: 0.0673s/iter; left time: 376.4244s
	iters: 900, epoch: 5 | loss: 0.1684480
	speed: 0.0674s/iter; left time: 370.4012s
	iters: 1000, epoch: 5 | loss: 0.1814033
	speed: 0.0671s/iter; left time: 361.8756s
Epoch: 5 cost time: 73.01367211341858
Epoch: 5, Steps: 1066 | Train Loss: 0.1731834 Vali Loss: 1.1624324 Test Loss: 1.1816150
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm1_96_336_Informer_ETTm1_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
mse:1.0589123964309692, mae:0.7615285515785217
INFO: Trainable parameter count: 0.01M
INFO: Trainable parameter count: 0.01M
INFO: Trainable parameter count: 0.02M
INFO: Trainable parameter count: 0.03M
INFO: Trainable parameter count: 0.29M
INFO: Trainable parameter count: 0.29M
INFO: Trainable parameter count: 0.55M
INFO: Trainable parameter count: 0.55M
INFO: Trainable parameter count: 0.81M
INFO: Trainable parameter count: 0.81M
INFO: Trainable parameter count: 1.08M
INFO: Trainable parameter count: 1.08M
INFO: Trainable parameter count: 2.12M
INFO: Trainable parameter count: 2.13M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.44M
INFO: Trainable parameter count: 3.44M
INFO: Trainable parameter count: 3.70M
INFO: Trainable parameter count: 3.70M
INFO: Trainable parameter count: 3.97M
INFO: Trainable parameter count: 3.97M
INFO: Trainable parameter count: 4.23M
INFO: Trainable parameter count: 4.23M
INFO: Trainable parameter count: 5.28M
INFO: Trainable parameter count: 5.28M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 7.12M
INFO: Trainable parameter count: 7.12M
INFO: Trainable parameter count: 7.12M
INFO: Trainable parameter count: 7.12M
INFO: Trainable parameter count: 7.12M
INFO: Trainable parameter count: 7.12M
INFO: Trainable parameter count: 7.38M
INFO: Trainable parameter count: 7.38M
INFO: Trainable parameter count: 7.64M
INFO: Trainable parameter count: 7.64M
INFO: Trainable parameter count: 7.91M
INFO: Trainable parameter count: 7.91M
INFO: Trainable parameter count: 8.17M
INFO: Trainable parameter count: 8.17M
INFO: Trainable parameter count: 8.43M
INFO: Trainable parameter count: 8.43M
INFO: Trainable parameter count: 8.69M
INFO: Trainable parameter count: 8.70M
INFO: Trainable parameter count: 8.96M
INFO: Trainable parameter count: 8.96M
INFO: Trainable parameter count: 9.22M
INFO: Trainable parameter count: 9.22M
INFO: Trainable parameter count: 10.27M
INFO: Trainable parameter count: 10.27M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.33M
INFO: Trainable parameter count: 11.33M
