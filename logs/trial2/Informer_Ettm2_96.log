Args in experiment:
Namespace(is_training=1, model_id='ETTm2_96_96', model='Informer', data='ETTm2', root_path='./dataset/', data_path='ETTm2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=5, use_multi_gpu=False, devices='0,1,2,3', test_flop=True)
Use GPU: cuda:5
>>>>>>>start training : ETTm2_96_96_Informer_ETTm2_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34369
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.2109173
	speed: 0.1112s/iter; left time: 1183.2254s
	iters: 200, epoch: 1 | loss: 0.1816139
	speed: 0.0477s/iter; left time: 502.3979s
	iters: 300, epoch: 1 | loss: 0.2488198
	speed: 0.0478s/iter; left time: 499.5048s
	iters: 400, epoch: 1 | loss: 0.2882794
	speed: 0.0475s/iter; left time: 491.1316s
	iters: 500, epoch: 1 | loss: 0.2652138
	speed: 0.0477s/iter; left time: 488.1328s
	iters: 600, epoch: 1 | loss: 0.1618151
	speed: 0.0480s/iter; left time: 486.5549s
	iters: 700, epoch: 1 | loss: 0.3431618
	speed: 0.0485s/iter; left time: 487.1768s
	iters: 800, epoch: 1 | loss: 0.2518802
	speed: 0.0482s/iter; left time: 478.7962s
	iters: 900, epoch: 1 | loss: 0.1889866
	speed: 0.0480s/iter; left time: 472.5530s
	iters: 1000, epoch: 1 | loss: 0.1583236
	speed: 0.0477s/iter; left time: 464.9972s
Epoch: 1 cost time: 57.89381170272827
Epoch: 1, Steps: 1074 | Train Loss: 0.2325068 Vali Loss: 0.2802107 Test Loss: 0.4096633
Validation loss decreased (inf --> 0.280211).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.1472035
	speed: 0.2499s/iter; left time: 2390.8796s
	iters: 200, epoch: 2 | loss: 0.2684937
	speed: 0.0484s/iter; left time: 458.1844s
	iters: 300, epoch: 2 | loss: 0.1506593
	speed: 0.0482s/iter; left time: 451.6294s
	iters: 400, epoch: 2 | loss: 0.1345502
	speed: 0.0484s/iter; left time: 448.1890s
	iters: 500, epoch: 2 | loss: 0.1234125
	speed: 0.0479s/iter; left time: 438.9366s
	iters: 600, epoch: 2 | loss: 0.1127569
	speed: 0.0489s/iter; left time: 443.0964s
	iters: 700, epoch: 2 | loss: 0.1128410
	speed: 0.0479s/iter; left time: 429.4554s
	iters: 800, epoch: 2 | loss: 0.1841630
	speed: 0.0482s/iter; left time: 427.6387s
	iters: 900, epoch: 2 | loss: 0.1999222
	speed: 0.0491s/iter; left time: 430.3613s
	iters: 1000, epoch: 2 | loss: 0.2395498
	speed: 0.0476s/iter; left time: 412.3093s
Epoch: 2 cost time: 53.87340044975281
Epoch: 2, Steps: 1074 | Train Loss: 0.1650710 Vali Loss: 0.2516419 Test Loss: 0.4075029
Validation loss decreased (0.280211 --> 0.251642).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.1262382
	speed: 0.2531s/iter; left time: 2149.8138s
	iters: 200, epoch: 3 | loss: 0.2455262
	speed: 0.0481s/iter; left time: 403.5452s
	iters: 300, epoch: 3 | loss: 0.1665876
	speed: 0.0480s/iter; left time: 398.4430s
	iters: 400, epoch: 3 | loss: 0.1268598
	speed: 0.0481s/iter; left time: 394.0126s
	iters: 500, epoch: 3 | loss: 0.1139002
	speed: 0.0480s/iter; left time: 388.7491s
	iters: 600, epoch: 3 | loss: 0.1439859
	speed: 0.0480s/iter; left time: 383.3563s
	iters: 700, epoch: 3 | loss: 0.1055308
	speed: 0.0488s/iter; left time: 385.1231s
	iters: 800, epoch: 3 | loss: 0.2095346
	speed: 0.0492s/iter; left time: 383.1167s
	iters: 900, epoch: 3 | loss: 0.1251117
	speed: 0.0486s/iter; left time: 374.2150s
	iters: 1000, epoch: 3 | loss: 0.1109563
	speed: 0.0477s/iter; left time: 362.2678s
Epoch: 3 cost time: 53.57158327102661
Epoch: 3, Steps: 1074 | Train Loss: 0.1331349 Vali Loss: 0.3646017 Test Loss: 0.5895846
EarlyStopping counter: 1 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.1420347
	speed: 0.2180s/iter; left time: 1617.6367s
	iters: 200, epoch: 4 | loss: 0.1191765
	speed: 0.0430s/iter; left time: 314.7121s
	iters: 300, epoch: 4 | loss: 0.1370550
	speed: 0.0465s/iter; left time: 335.5601s
	iters: 400, epoch: 4 | loss: 0.1095932
	speed: 0.0461s/iter; left time: 328.3903s
	iters: 500, epoch: 4 | loss: 0.0937019
	speed: 0.0456s/iter; left time: 320.2098s
	iters: 600, epoch: 4 | loss: 0.0977955
	speed: 0.0448s/iter; left time: 310.1319s
	iters: 700, epoch: 4 | loss: 0.0851000
	speed: 0.0444s/iter; left time: 302.7202s
	iters: 800, epoch: 4 | loss: 0.1005197
	speed: 0.0434s/iter; left time: 291.3692s
	iters: 900, epoch: 4 | loss: 0.1263561
	speed: 0.0436s/iter; left time: 288.3906s
	iters: 1000, epoch: 4 | loss: 0.0903433
	speed: 0.0440s/iter; left time: 286.8817s
Epoch: 4 cost time: 49.286312103271484
Epoch: 4, Steps: 1074 | Train Loss: 0.1145658 Vali Loss: 0.4732629 Test Loss: 0.7873495
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.1134887
	speed: 0.2217s/iter; left time: 1406.5018s
	iters: 200, epoch: 5 | loss: 0.1290913
	speed: 0.0436s/iter; left time: 272.3237s
	iters: 300, epoch: 5 | loss: 0.1081691
	speed: 0.0438s/iter; left time: 269.3022s
	iters: 400, epoch: 5 | loss: 0.1328428
	speed: 0.0438s/iter; left time: 264.8411s
	iters: 500, epoch: 5 | loss: 0.0999686
	speed: 0.0476s/iter; left time: 282.8280s
	iters: 600, epoch: 5 | loss: 0.1231449
	speed: 0.0472s/iter; left time: 276.1513s
	iters: 700, epoch: 5 | loss: 0.1018740
	speed: 0.0477s/iter; left time: 273.9850s
	iters: 800, epoch: 5 | loss: 0.0915956
	speed: 0.0481s/iter; left time: 271.7120s
	iters: 900, epoch: 5 | loss: 0.0865897
	speed: 0.0447s/iter; left time: 247.8336s
	iters: 1000, epoch: 5 | loss: 0.0986237
	speed: 0.0440s/iter; left time: 239.3215s
Epoch: 5 cost time: 50.41233205795288
Epoch: 5, Steps: 1074 | Train Loss: 0.1043707 Vali Loss: 0.4837433 Test Loss: 0.7590359
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm2_96_96_Informer_ETTm2_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
mse:0.407928466796875, mae:0.4949638843536377
INFO: Trainable parameter count: 0.01M
INFO: Trainable parameter count: 0.01M
INFO: Trainable parameter count: 0.02M
INFO: Trainable parameter count: 0.03M
INFO: Trainable parameter count: 0.29M
INFO: Trainable parameter count: 0.29M
INFO: Trainable parameter count: 0.55M
INFO: Trainable parameter count: 0.55M
INFO: Trainable parameter count: 0.81M
INFO: Trainable parameter count: 0.81M
INFO: Trainable parameter count: 1.08M
INFO: Trainable parameter count: 1.08M
INFO: Trainable parameter count: 2.12M
INFO: Trainable parameter count: 2.13M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.44M
INFO: Trainable parameter count: 3.44M
INFO: Trainable parameter count: 3.70M
INFO: Trainable parameter count: 3.70M
INFO: Trainable parameter count: 3.97M
INFO: Trainable parameter count: 3.97M
INFO: Trainable parameter count: 4.23M
INFO: Trainable parameter count: 4.23M
INFO: Trainable parameter count: 5.28M
INFO: Trainable parameter count: 5.28M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 7.12M
INFO: Trainable parameter count: 7.12M
INFO: Trainable parameter count: 7.12M
INFO: Trainable parameter count: 7.12M
INFO: Trainable parameter count: 7.12M
INFO: Trainable parameter count: 7.12M
INFO: Trainable parameter count: 7.38M
INFO: Trainable parameter count: 7.38M
INFO: Trainable parameter count: 7.64M
INFO: Trainable parameter count: 7.64M
INFO: Trainable parameter count: 7.91M
INFO: Trainable parameter count: 7.91M
INFO: Trainable parameter count: 8.17M
INFO: Trainable parameter count: 8.17M
INFO: Trainable parameter count: 8.43M
INFO: Trainable parameter count: 8.43M
INFO: Trainable parameter count: 8.69M
INFO: Trainable parameter count: 8.70M
INFO: Trainable parameter count: 8.96M
INFO: Trainable parameter count: 8.96M
INFO: Trainable parameter count: 9.22M
INFO: Trainable parameter count: 9.22M
INFO: Trainable parameter count: 10.27M
INFO: Trainable parameter count: 10.27M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.33M
INFO: Trainable parameter count: 11.33M
