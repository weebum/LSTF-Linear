Args in experiment:
Namespace(is_training=1, model_id='ETTh2_96_96', model='DLinear', data='ETTh2', root_path='./dataset/', data_path='ETTh2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=1, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=3, learning_rate=0.05, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=3, use_multi_gpu=False, devices='0,1,2,3', test_flop=True)
Use GPU: cuda:3
>>>>>>>start training : ETTh2_96_96_DLinear_ETTh2_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8449
val 2785
test 2785
Epoch: 1 cost time: 7.678199529647827
Epoch: 1, Steps: 264 | Train Loss: 0.7299042 Vali Loss: 0.3402171 Test Loss: 0.5081632
Validation loss decreased (inf --> 0.340217).  Saving model ...
Updating learning rate to 0.05
Epoch: 2 cost time: 2.398641586303711
Epoch: 2, Steps: 264 | Train Loss: 0.6141129 Vali Loss: 0.3575391 Test Loss: 0.5748721
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.025
Epoch: 3 cost time: 2.3728818893432617
Epoch: 3, Steps: 264 | Train Loss: 0.4871955 Vali Loss: 0.2895418 Test Loss: 0.4337642
Validation loss decreased (0.340217 --> 0.289542).  Saving model ...
Updating learning rate to 0.0125
Epoch: 4 cost time: 2.1868672370910645
Epoch: 4, Steps: 264 | Train Loss: 0.4368362 Vali Loss: 0.2484970 Test Loss: 0.3622044
Validation loss decreased (0.289542 --> 0.248497).  Saving model ...
Updating learning rate to 0.00625
Epoch: 5 cost time: 2.134585380554199
Epoch: 5, Steps: 264 | Train Loss: 0.4156545 Vali Loss: 0.3292283 Test Loss: 0.5393081
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.003125
Epoch: 6 cost time: 2.0916898250579834
Epoch: 6, Steps: 264 | Train Loss: 0.4062449 Vali Loss: 0.2309423 Test Loss: 0.3288221
Validation loss decreased (0.248497 --> 0.230942).  Saving model ...
Updating learning rate to 0.0015625
Epoch: 7 cost time: 2.107663631439209
Epoch: 7, Steps: 264 | Train Loss: 0.3990710 Vali Loss: 0.2298661 Test Loss: 0.3291596
Validation loss decreased (0.230942 --> 0.229866).  Saving model ...
Updating learning rate to 0.00078125
Epoch: 8 cost time: 2.0689613819122314
Epoch: 8, Steps: 264 | Train Loss: 0.3965824 Vali Loss: 0.2303228 Test Loss: 0.3309304
EarlyStopping counter: 1 out of 3
Updating learning rate to 0.000390625
Epoch: 9 cost time: 2.027884006500244
Epoch: 9, Steps: 264 | Train Loss: 0.3943492 Vali Loss: 0.2473385 Test Loss: 0.3668547
EarlyStopping counter: 2 out of 3
Updating learning rate to 0.0001953125
Epoch: 10 cost time: 2.0426547527313232
Epoch: 10, Steps: 264 | Train Loss: 0.3936589 Vali Loss: 0.2426783 Test Loss: 0.3570248
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTh2_96_96_DLinear_ETTh2_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
mse:0.3291597366333008, mae:0.3804686665534973
INFO: Trainable parameter count: 0.01M
INFO: Trainable parameter count: 0.01M
INFO: Trainable parameter count: 0.02M
INFO: Trainable parameter count: 0.02M
Model(
  18.62 k, 100.000% Params, 130.06 KMac, 100.000% MACs, 
  (decompsition): series_decomp(
    0, 0.000% Params, 840.0 Mac, 0.646% MACs, 
    (moving_avg): moving_avg(
      0, 0.000% Params, 840.0 Mac, 0.646% MACs, 
      (avg): AvgPool1d(0, 0.000% Params, 840.0 Mac, 0.646% MACs, kernel_size=(25,), stride=(1,), padding=(0,))
    )
  )
  (Linear_Seasonal): Linear(9.31 k, 50.000% Params, 64.61 KMac, 49.677% MACs, in_features=96, out_features=96, bias=True)
  (Linear_Trend): Linear(9.31 k, 50.000% Params, 64.61 KMac, 49.677% MACs, in_features=96, out_features=96, bias=True)
)
Computational complexity:       130.06 KMac
Number of parameters:           18.62 k 
