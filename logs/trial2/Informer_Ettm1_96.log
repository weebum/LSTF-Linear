Args in experiment:
Namespace(is_training=1, model_id='ETTm1_96_96', model='Informer', data='ETTm1', root_path='./dataset/', data_path='ETTm1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=4, use_multi_gpu=False, devices='0,1,2,3', test_flop=True)
Use GPU: cuda:4
>>>>>>>start training : ETTm1_96_96_Informer_ETTm1_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34369
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.4241927
	speed: 0.1137s/iter; left time: 1209.9296s
	iters: 200, epoch: 1 | loss: 0.3418069
	speed: 0.0488s/iter; left time: 514.5781s
	iters: 300, epoch: 1 | loss: 0.3545225
	speed: 0.0487s/iter; left time: 508.7538s
	iters: 400, epoch: 1 | loss: 0.2814945
	speed: 0.0496s/iter; left time: 513.2877s
	iters: 500, epoch: 1 | loss: 0.3682227
	speed: 0.0492s/iter; left time: 503.5424s
	iters: 600, epoch: 1 | loss: 0.2545127
	speed: 0.0481s/iter; left time: 487.7542s
	iters: 700, epoch: 1 | loss: 0.2988605
	speed: 0.0474s/iter; left time: 476.0553s
	iters: 800, epoch: 1 | loss: 0.2744755
	speed: 0.0479s/iter; left time: 476.0038s
	iters: 900, epoch: 1 | loss: 0.2251126
	speed: 0.0478s/iter; left time: 470.5802s
	iters: 1000, epoch: 1 | loss: 0.3017815
	speed: 0.0477s/iter; left time: 464.8893s
Epoch: 1 cost time: 58.54755878448486
Epoch: 1, Steps: 1074 | Train Loss: 0.3112429 Vali Loss: 0.6724584 Test Loss: 0.6256841
Validation loss decreased (inf --> 0.672458).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2626511
	speed: 0.2446s/iter; left time: 2340.0351s
	iters: 200, epoch: 2 | loss: 0.2347353
	speed: 0.0472s/iter; left time: 446.4625s
	iters: 300, epoch: 2 | loss: 0.2473095
	speed: 0.0481s/iter; left time: 450.7662s
	iters: 400, epoch: 2 | loss: 0.2237027
	speed: 0.0479s/iter; left time: 443.6321s
	iters: 500, epoch: 2 | loss: 0.2294767
	speed: 0.0481s/iter; left time: 441.1221s
	iters: 600, epoch: 2 | loss: 0.2300948
	speed: 0.0488s/iter; left time: 442.0450s
	iters: 700, epoch: 2 | loss: 0.2333437
	speed: 0.0480s/iter; left time: 430.4731s
	iters: 800, epoch: 2 | loss: 0.2172793
	speed: 0.0486s/iter; left time: 430.9124s
	iters: 900, epoch: 2 | loss: 0.2007921
	speed: 0.0482s/iter; left time: 422.5324s
	iters: 1000, epoch: 2 | loss: 0.2890194
	speed: 0.0480s/iter; left time: 416.0809s
Epoch: 2 cost time: 53.47024726867676
Epoch: 2, Steps: 1074 | Train Loss: 0.2286925 Vali Loss: 0.7058875 Test Loss: 0.6752709
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.1834148
	speed: 0.2499s/iter; left time: 2122.2961s
	iters: 200, epoch: 3 | loss: 0.2156042
	speed: 0.0486s/iter; left time: 408.1520s
	iters: 300, epoch: 3 | loss: 0.1855958
	speed: 0.0476s/iter; left time: 394.7300s
	iters: 400, epoch: 3 | loss: 0.1945042
	speed: 0.0481s/iter; left time: 394.3101s
	iters: 500, epoch: 3 | loss: 0.1671391
	speed: 0.0490s/iter; left time: 396.9482s
	iters: 600, epoch: 3 | loss: 0.1573622
	speed: 0.0480s/iter; left time: 383.6673s
	iters: 700, epoch: 3 | loss: 0.1675124
	speed: 0.0485s/iter; left time: 382.9959s
	iters: 800, epoch: 3 | loss: 0.1849625
	speed: 0.0481s/iter; left time: 374.9085s
	iters: 900, epoch: 3 | loss: 0.1925447
	speed: 0.0480s/iter; left time: 369.2787s
	iters: 1000, epoch: 3 | loss: 0.1498656
	speed: 0.0485s/iter; left time: 368.2347s
Epoch: 3 cost time: 53.69318914413452
Epoch: 3, Steps: 1074 | Train Loss: 0.1836092 Vali Loss: 0.7805924 Test Loss: 0.8189749
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.1342209
	speed: 0.2445s/iter; left time: 1813.6039s
	iters: 200, epoch: 4 | loss: 0.1699015
	speed: 0.0436s/iter; left time: 318.9155s
	iters: 300, epoch: 4 | loss: 0.1726897
	speed: 0.0434s/iter; left time: 313.1727s
	iters: 400, epoch: 4 | loss: 0.1371187
	speed: 0.0430s/iter; left time: 305.7768s
	iters: 500, epoch: 4 | loss: 0.1559616
	speed: 0.0434s/iter; left time: 304.9237s
	iters: 600, epoch: 4 | loss: 0.1554839
	speed: 0.0436s/iter; left time: 301.6135s
	iters: 700, epoch: 4 | loss: 0.1345654
	speed: 0.0430s/iter; left time: 293.4246s
	iters: 800, epoch: 4 | loss: 0.1340376
	speed: 0.0466s/iter; left time: 313.0670s
	iters: 900, epoch: 4 | loss: 0.1709601
	speed: 0.0472s/iter; left time: 312.5281s
	iters: 1000, epoch: 4 | loss: 0.1389258
	speed: 0.0447s/iter; left time: 291.4278s
Epoch: 4 cost time: 49.53911304473877
Epoch: 4, Steps: 1074 | Train Loss: 0.1576814 Vali Loss: 0.8288031 Test Loss: 0.8191813
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm1_96_96_Informer_ETTm1_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
mse:0.6256442666053772, mae:0.561184823513031
INFO: Trainable parameter count: 0.01M
INFO: Trainable parameter count: 0.01M
INFO: Trainable parameter count: 0.02M
INFO: Trainable parameter count: 0.03M
INFO: Trainable parameter count: 0.29M
INFO: Trainable parameter count: 0.29M
INFO: Trainable parameter count: 0.55M
INFO: Trainable parameter count: 0.55M
INFO: Trainable parameter count: 0.81M
INFO: Trainable parameter count: 0.81M
INFO: Trainable parameter count: 1.08M
INFO: Trainable parameter count: 1.08M
INFO: Trainable parameter count: 2.12M
INFO: Trainable parameter count: 2.13M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.18M
INFO: Trainable parameter count: 3.44M
INFO: Trainable parameter count: 3.44M
INFO: Trainable parameter count: 3.70M
INFO: Trainable parameter count: 3.70M
INFO: Trainable parameter count: 3.97M
INFO: Trainable parameter count: 3.97M
INFO: Trainable parameter count: 4.23M
INFO: Trainable parameter count: 4.23M
INFO: Trainable parameter count: 5.28M
INFO: Trainable parameter count: 5.28M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 6.33M
INFO: Trainable parameter count: 7.12M
INFO: Trainable parameter count: 7.12M
INFO: Trainable parameter count: 7.12M
INFO: Trainable parameter count: 7.12M
INFO: Trainable parameter count: 7.12M
INFO: Trainable parameter count: 7.12M
INFO: Trainable parameter count: 7.38M
INFO: Trainable parameter count: 7.38M
INFO: Trainable parameter count: 7.64M
INFO: Trainable parameter count: 7.64M
INFO: Trainable parameter count: 7.91M
INFO: Trainable parameter count: 7.91M
INFO: Trainable parameter count: 8.17M
INFO: Trainable parameter count: 8.17M
INFO: Trainable parameter count: 8.43M
INFO: Trainable parameter count: 8.43M
INFO: Trainable parameter count: 8.69M
INFO: Trainable parameter count: 8.70M
INFO: Trainable parameter count: 8.96M
INFO: Trainable parameter count: 8.96M
INFO: Trainable parameter count: 9.22M
INFO: Trainable parameter count: 9.22M
INFO: Trainable parameter count: 10.27M
INFO: Trainable parameter count: 10.27M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.32M
INFO: Trainable parameter count: 11.33M
INFO: Trainable parameter count: 11.33M
