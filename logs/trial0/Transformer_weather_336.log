Args in experiment:
Namespace(is_training=1, model_id='weather_96_336', model='Transformer', data='custom', root_path='./dataset/', data_path='weather.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=336, individual=False, embed_type=0, enc_in=21, dec_in=21, c_out=21, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=2, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=9, use_multi_gpu=False, devices='0,1,2,3', test_flop=False)
Use GPU: cuda:9
>>>>>>>start training : weather_96_336_Transformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 36456
val 4935
test 10204
	iters: 100, epoch: 1 | loss: 0.5152584
	speed: 0.1126s/iter; left time: 245.4075s
	iters: 200, epoch: 1 | loss: 0.3087309
	speed: 0.0541s/iter; left time: 112.4895s
	iters: 300, epoch: 1 | loss: 0.3435571
	speed: 0.0532s/iter; left time: 105.3802s
	iters: 400, epoch: 1 | loss: 0.4397208
	speed: 0.0532s/iter; left time: 99.9089s
	iters: 500, epoch: 1 | loss: 0.5311607
	speed: 0.0532s/iter; left time: 94.6385s
	iters: 600, epoch: 1 | loss: 0.3602894
	speed: 0.0531s/iter; left time: 89.2374s
	iters: 700, epoch: 1 | loss: 0.2201596
	speed: 0.0523s/iter; left time: 82.5562s
	iters: 800, epoch: 1 | loss: 0.3937175
	speed: 0.0536s/iter; left time: 79.2680s
	iters: 900, epoch: 1 | loss: 0.3640558
	speed: 0.0541s/iter; left time: 74.6206s
	iters: 1000, epoch: 1 | loss: 0.5595502
	speed: 0.0554s/iter; left time: 70.9099s
	iters: 1100, epoch: 1 | loss: 0.5353276
	speed: 0.0564s/iter; left time: 66.5116s
Epoch: 1 cost time: 67.2874710559845
Epoch: 1, Steps: 1139 | Train Loss: 0.4300856 Vali Loss: 0.7008231 Test Loss: 0.6412683
Validation loss decreased (inf --> 0.700823).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.4305283
	speed: 0.2353s/iter; left time: 244.7256s
	iters: 200, epoch: 2 | loss: 0.2132369
	speed: 0.0536s/iter; left time: 50.3535s
	iters: 300, epoch: 2 | loss: 0.1848035
	speed: 0.0524s/iter; left time: 44.0366s
	iters: 400, epoch: 2 | loss: 0.4443454
	speed: 0.0536s/iter; left time: 39.6964s
	iters: 500, epoch: 2 | loss: 0.2927158
	speed: 0.0524s/iter; left time: 33.5668s
	iters: 600, epoch: 2 | loss: 0.3979852
	speed: 0.0530s/iter; left time: 28.6466s
	iters: 700, epoch: 2 | loss: 0.2614320
	speed: 0.0550s/iter; left time: 24.1783s
	iters: 800, epoch: 2 | loss: 0.2015616
	speed: 0.0531s/iter; left time: 18.0709s
	iters: 900, epoch: 2 | loss: 0.2038255
	speed: 0.0536s/iter; left time: 12.8662s
	iters: 1000, epoch: 2 | loss: 0.1868822
	speed: 0.0533s/iter; left time: 7.4640s
	iters: 1100, epoch: 2 | loss: 0.6348087
	speed: 0.0532s/iter; left time: 2.1270s
Epoch: 2 cost time: 62.973644733428955
Epoch: 2, Steps: 1139 | Train Loss: 0.2948656 Vali Loss: 0.7182399 Test Loss: 0.6922744
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
>>>>>>>testing : weather_96_336_Transformer_custom_ftM_sl96_ll48_pl336_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10204
mse:0.6412679553031921, mae:0.5771418809890747
