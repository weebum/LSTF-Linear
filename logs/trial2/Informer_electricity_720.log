Args in experiment:
Namespace(is_training=1, model_id='electricity_96_720', model='Informer', data='custom', root_path='./dataset/', data_path='electricity.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=720, individual=False, embed_type=0, enc_in=321, dec_in=321, c_out=321, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=1, use_multi_gpu=False, devices='0,1,2,3', test_flop=True)
Use GPU: cuda:1
>>>>>>>start training : electricity_96_720_Informer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 17597
val 1913
test 4541
	iters: 100, epoch: 1 | loss: 0.8650661
	speed: 0.1800s/iter; left time: 970.1254s
	iters: 200, epoch: 1 | loss: 0.8160181
	speed: 0.1333s/iter; left time: 705.2376s
	iters: 300, epoch: 1 | loss: 0.8248097
	speed: 0.1355s/iter; left time: 703.5551s
	iters: 400, epoch: 1 | loss: 0.7697707
	speed: 0.1349s/iter; left time: 686.8827s
	iters: 500, epoch: 1 | loss: 0.7370564
	speed: 0.1358s/iter; left time: 677.6769s
Epoch: 1 cost time: 78.32996726036072
Epoch: 1, Steps: 549 | Train Loss: 0.8218532 Vali Loss: 0.7759627 Test Loss: 0.9046312
Validation loss decreased (inf --> 0.775963).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.7361782
	speed: 0.4877s/iter; left time: 2361.2172s
	iters: 200, epoch: 2 | loss: 0.7199509
	speed: 0.1346s/iter; left time: 638.4109s
	iters: 300, epoch: 2 | loss: 0.7128248
	speed: 0.1344s/iter; left time: 623.8131s
	iters: 400, epoch: 2 | loss: 0.6185834
	speed: 0.1309s/iter; left time: 594.3335s
	iters: 500, epoch: 2 | loss: 0.6203206
	speed: 0.1273s/iter; left time: 565.5144s
Epoch: 2 cost time: 75.90698385238647
Epoch: 2, Steps: 549 | Train Loss: 0.6840440 Vali Loss: 0.5812404 Test Loss: 0.6785586
Validation loss decreased (0.775963 --> 0.581240).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3580434
	speed: 0.4154s/iter; left time: 1783.1255s
	iters: 200, epoch: 3 | loss: 0.3060157
	speed: 0.1244s/iter; left time: 521.6759s
	iters: 300, epoch: 3 | loss: 0.2775327
	speed: 0.1257s/iter; left time: 514.6328s
	iters: 400, epoch: 3 | loss: 0.2554382
	speed: 0.1249s/iter; left time: 498.8686s
	iters: 500, epoch: 3 | loss: 0.2620734
	speed: 0.1256s/iter; left time: 488.8899s
Epoch: 3 cost time: 70.86584186553955
Epoch: 3, Steps: 549 | Train Loss: 0.3100483 Vali Loss: 0.3488450 Test Loss: 0.4147777
Validation loss decreased (0.581240 --> 0.348845).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2398320
	speed: 0.4171s/iter; left time: 1561.6694s
	iters: 200, epoch: 4 | loss: 0.2464505
	speed: 0.1272s/iter; left time: 463.6562s
	iters: 300, epoch: 4 | loss: 0.2406033
	speed: 0.1256s/iter; left time: 445.0856s
	iters: 400, epoch: 4 | loss: 0.2384348
	speed: 0.1246s/iter; left time: 429.2744s
	iters: 500, epoch: 4 | loss: 0.2252227
	speed: 0.1257s/iter; left time: 420.4626s
Epoch: 4 cost time: 71.43360710144043
Epoch: 4, Steps: 549 | Train Loss: 0.2389294 Vali Loss: 0.3452033 Test Loss: 0.4067387
Validation loss decreased (0.348845 --> 0.345203).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2449985
	speed: 0.4206s/iter; left time: 1343.7001s
	iters: 200, epoch: 5 | loss: 0.2216641
	speed: 0.1352s/iter; left time: 418.4770s
	iters: 300, epoch: 5 | loss: 0.2221766
	speed: 0.1355s/iter; left time: 405.8721s
	iters: 400, epoch: 5 | loss: 0.2240093
	speed: 0.1362s/iter; left time: 394.2787s
	iters: 500, epoch: 5 | loss: 0.2312054
	speed: 0.1358s/iter; left time: 379.4716s
Epoch: 5 cost time: 76.42969489097595
Epoch: 5, Steps: 549 | Train Loss: 0.2237536 Vali Loss: 0.3402390 Test Loss: 0.3960465
Validation loss decreased (0.345203 --> 0.340239).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.2398238
	speed: 0.4952s/iter; left time: 1310.3306s
	iters: 200, epoch: 6 | loss: 0.2083239
	speed: 0.1366s/iter; left time: 347.7528s
	iters: 300, epoch: 6 | loss: 0.2183546
	speed: 0.1357s/iter; left time: 331.8465s
	iters: 400, epoch: 6 | loss: 0.2250457
	speed: 0.1371s/iter; left time: 321.5928s
	iters: 500, epoch: 6 | loss: 0.2266667
	speed: 0.1374s/iter; left time: 308.6908s
Epoch: 6 cost time: 78.09181261062622
Epoch: 6, Steps: 549 | Train Loss: 0.2171334 Vali Loss: 0.3347988 Test Loss: 0.3936300
Validation loss decreased (0.340239 --> 0.334799).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.2083380
	speed: 0.4379s/iter; left time: 918.2270s
	iters: 200, epoch: 7 | loss: 0.2126937
	speed: 0.1251s/iter; left time: 249.8334s
	iters: 300, epoch: 7 | loss: 0.2131308
	speed: 0.1244s/iter; left time: 235.9836s
	iters: 400, epoch: 7 | loss: 0.2055291
	speed: 0.1269s/iter; left time: 228.0345s
	iters: 500, epoch: 7 | loss: 0.2189855
	speed: 0.1250s/iter; left time: 212.0771s
Epoch: 7 cost time: 70.97352313995361
Epoch: 7, Steps: 549 | Train Loss: 0.2142968 Vali Loss: 0.3350358 Test Loss: 0.3937295
EarlyStopping counter: 1 out of 3
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.2022552
	speed: 0.4190s/iter; left time: 648.6267s
	iters: 200, epoch: 8 | loss: 0.2179519
	speed: 0.1253s/iter; left time: 181.3945s
	iters: 300, epoch: 8 | loss: 0.2126006
	speed: 0.1265s/iter; left time: 170.4664s
	iters: 400, epoch: 8 | loss: 0.2183506
	speed: 0.1253s/iter; left time: 156.3576s
	iters: 500, epoch: 8 | loss: 0.2065077
	speed: 0.1271s/iter; left time: 145.9366s
Epoch: 8 cost time: 71.3616271018982
Epoch: 8, Steps: 549 | Train Loss: 0.2127481 Vali Loss: 0.3327845 Test Loss: 0.3928278
Validation loss decreased (0.334799 --> 0.332785).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.2067133
	speed: 0.4228s/iter; left time: 422.3723s
	iters: 200, epoch: 9 | loss: 0.2092014
	speed: 0.1238s/iter; left time: 111.2598s
	iters: 300, epoch: 9 | loss: 0.2106017
	speed: 0.1255s/iter; left time: 100.3119s
	iters: 400, epoch: 9 | loss: 0.2143738
	speed: 0.1266s/iter; left time: 88.4970s
	iters: 500, epoch: 9 | loss: 0.2067049
	speed: 0.1276s/iter; left time: 76.4139s
Epoch: 9 cost time: 71.22003555297852
Epoch: 9, Steps: 549 | Train Loss: 0.2119388 Vali Loss: 0.3342807 Test Loss: 0.3929949
EarlyStopping counter: 1 out of 3
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.2085096
	speed: 0.4197s/iter; left time: 188.8826s
	iters: 200, epoch: 10 | loss: 0.2142777
	speed: 0.1263s/iter; left time: 44.1915s
	iters: 300, epoch: 10 | loss: 0.2055224
	speed: 0.1263s/iter; left time: 31.5627s
	iters: 400, epoch: 10 | loss: 0.2059269
	speed: 0.1242s/iter; left time: 18.6309s
	iters: 500, epoch: 10 | loss: 0.2078351
	speed: 0.1256s/iter; left time: 6.2812s
Epoch: 10 cost time: 70.97448706626892
Epoch: 10, Steps: 549 | Train Loss: 0.2115313 Vali Loss: 0.3344306 Test Loss: 0.3933088
EarlyStopping counter: 2 out of 3
Updating learning rate to 1.953125e-07
>>>>>>>testing : electricity_96_720_Informer_custom_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
mse:0.3928791284561157, mae:0.455644816160202
INFO: Trainable parameter count: 0.49M
INFO: Trainable parameter count: 0.50M
INFO: Trainable parameter count: 0.99M
INFO: Trainable parameter count: 0.99M
INFO: Trainable parameter count: 1.25M
INFO: Trainable parameter count: 1.25M
INFO: Trainable parameter count: 1.52M
INFO: Trainable parameter count: 1.52M
INFO: Trainable parameter count: 1.78M
INFO: Trainable parameter count: 1.78M
INFO: Trainable parameter count: 2.04M
INFO: Trainable parameter count: 2.04M
INFO: Trainable parameter count: 3.09M
INFO: Trainable parameter count: 3.09M
INFO: Trainable parameter count: 4.14M
INFO: Trainable parameter count: 4.14M
INFO: Trainable parameter count: 4.14M
INFO: Trainable parameter count: 4.14M
INFO: Trainable parameter count: 4.14M
INFO: Trainable parameter count: 4.14M
INFO: Trainable parameter count: 4.40M
INFO: Trainable parameter count: 4.41M
INFO: Trainable parameter count: 4.67M
INFO: Trainable parameter count: 4.67M
INFO: Trainable parameter count: 4.93M
INFO: Trainable parameter count: 4.93M
INFO: Trainable parameter count: 5.19M
INFO: Trainable parameter count: 5.19M
INFO: Trainable parameter count: 6.24M
INFO: Trainable parameter count: 6.24M
INFO: Trainable parameter count: 7.29M
INFO: Trainable parameter count: 7.29M
INFO: Trainable parameter count: 7.29M
INFO: Trainable parameter count: 7.29M
INFO: Trainable parameter count: 7.29M
INFO: Trainable parameter count: 7.29M
INFO: Trainable parameter count: 8.08M
INFO: Trainable parameter count: 8.08M
INFO: Trainable parameter count: 8.08M
INFO: Trainable parameter count: 8.08M
INFO: Trainable parameter count: 8.08M
INFO: Trainable parameter count: 8.08M
INFO: Trainable parameter count: 8.35M
INFO: Trainable parameter count: 8.35M
INFO: Trainable parameter count: 8.61M
INFO: Trainable parameter count: 8.61M
INFO: Trainable parameter count: 8.87M
INFO: Trainable parameter count: 8.87M
INFO: Trainable parameter count: 9.13M
INFO: Trainable parameter count: 9.13M
INFO: Trainable parameter count: 9.40M
INFO: Trainable parameter count: 9.40M
INFO: Trainable parameter count: 9.66M
INFO: Trainable parameter count: 9.66M
INFO: Trainable parameter count: 9.92M
INFO: Trainable parameter count: 9.92M
INFO: Trainable parameter count: 10.18M
INFO: Trainable parameter count: 10.19M
INFO: Trainable parameter count: 11.23M
INFO: Trainable parameter count: 11.24M
INFO: Trainable parameter count: 12.28M
INFO: Trainable parameter count: 12.28M
INFO: Trainable parameter count: 12.29M
INFO: Trainable parameter count: 12.29M
INFO: Trainable parameter count: 12.29M
INFO: Trainable parameter count: 12.29M
INFO: Trainable parameter count: 12.29M
INFO: Trainable parameter count: 12.29M
INFO: Trainable parameter count: 12.29M
INFO: Trainable parameter count: 12.29M
INFO: Trainable parameter count: 12.45M
INFO: Trainable parameter count: 12.45M
