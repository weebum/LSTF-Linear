Args in experiment:
Namespace(is_training=1, model_id='ETTm2_96_720', model='Autoformer', data='ETTm2', root_path='./dataset/', data_path='ETTm2.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=720, individual=False, embed_type=0, enc_in=7, dec_in=7, c_out=7, d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=2048, moving_avg=25, factor=3, distil=True, dropout=0.05, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='mse', lradj='type1', use_amp=False, use_gpu=True, gpu=5, use_multi_gpu=False, devices='0,1,2,3', test_flop=True)
Use GPU: cuda:5
>>>>>>>start training : ETTm2_96_720_Autoformer_ETTm2_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33745
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.2828370
	speed: 0.2337s/iter; left time: 2439.7022s
	iters: 200, epoch: 1 | loss: 0.6628669
	speed: 0.1745s/iter; left time: 1804.3516s
	iters: 300, epoch: 1 | loss: 0.3768995
	speed: 0.1747s/iter; left time: 1789.5011s
	iters: 400, epoch: 1 | loss: 0.5626944
	speed: 0.1721s/iter; left time: 1745.2140s
	iters: 500, epoch: 1 | loss: 0.9631811
	speed: 0.1724s/iter; left time: 1730.6621s
	iters: 600, epoch: 1 | loss: 0.8019565
	speed: 0.1725s/iter; left time: 1714.7752s
	iters: 700, epoch: 1 | loss: 1.0166062
	speed: 0.1755s/iter; left time: 1726.7213s
	iters: 800, epoch: 1 | loss: 0.3443562
	speed: 0.1732s/iter; left time: 1686.6905s
	iters: 900, epoch: 1 | loss: 0.4139938
	speed: 0.1753s/iter; left time: 1690.2690s
	iters: 1000, epoch: 1 | loss: 0.2672150
	speed: 0.1753s/iter; left time: 1672.0693s
Epoch: 1 cost time: 189.44872379302979
Epoch: 1, Steps: 1054 | Train Loss: 0.5898022 Vali Loss: 0.3348137 Test Loss: 0.4644390
Validation loss decreased (inf --> 0.334814).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.6861308
	speed: 1.2734s/iter; left time: 11953.5954s
	iters: 200, epoch: 2 | loss: 0.5989819
	speed: 0.1743s/iter; left time: 1618.6226s
	iters: 300, epoch: 2 | loss: 0.5735095
	speed: 0.1750s/iter; left time: 1608.0314s
	iters: 400, epoch: 2 | loss: 0.3023883
	speed: 0.1718s/iter; left time: 1561.3148s
	iters: 500, epoch: 2 | loss: 0.7159753
	speed: 0.1701s/iter; left time: 1528.4210s
	iters: 600, epoch: 2 | loss: 0.4706158
	speed: 0.1720s/iter; left time: 1528.6242s
	iters: 700, epoch: 2 | loss: 0.3204715
	speed: 0.1722s/iter; left time: 1512.9299s
	iters: 800, epoch: 2 | loss: 0.3873564
	speed: 0.1744s/iter; left time: 1514.8318s
	iters: 900, epoch: 2 | loss: 0.4048249
	speed: 0.1746s/iter; left time: 1499.1090s
	iters: 1000, epoch: 2 | loss: 0.4555869
	speed: 0.1724s/iter; left time: 1463.2997s
Epoch: 2 cost time: 184.6404459476471
Epoch: 2, Steps: 1054 | Train Loss: 0.5452791 Vali Loss: 0.3629911 Test Loss: 0.5172967
EarlyStopping counter: 1 out of 3
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7087942
	speed: 1.2800s/iter; left time: 10665.8411s
	iters: 200, epoch: 3 | loss: 0.4493763
	speed: 0.1754s/iter; left time: 1444.0540s
	iters: 300, epoch: 3 | loss: 0.3093065
	speed: 0.1743s/iter; left time: 1417.2140s
	iters: 400, epoch: 3 | loss: 0.7024035
	speed: 0.1733s/iter; left time: 1391.7602s
	iters: 500, epoch: 3 | loss: 0.2946774
	speed: 0.1718s/iter; left time: 1363.1883s
	iters: 600, epoch: 3 | loss: 0.8143685
	speed: 0.1729s/iter; left time: 1354.2012s
	iters: 700, epoch: 3 | loss: 0.5094402
	speed: 0.1739s/iter; left time: 1345.1279s
	iters: 800, epoch: 3 | loss: 0.7445549
	speed: 0.1749s/iter; left time: 1335.0866s
	iters: 900, epoch: 3 | loss: 0.5789121
	speed: 0.1708s/iter; left time: 1286.8060s
	iters: 1000, epoch: 3 | loss: 0.3332022
	speed: 0.1752s/iter; left time: 1302.0620s
Epoch: 3 cost time: 185.07889938354492
Epoch: 3, Steps: 1054 | Train Loss: 0.5213481 Vali Loss: 0.3468372 Test Loss: 0.4987275
EarlyStopping counter: 2 out of 3
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.4641394
	speed: 1.1979s/iter; left time: 8719.2780s
	iters: 200, epoch: 4 | loss: 0.5168909
	speed: 0.1748s/iter; left time: 1255.0571s
	iters: 300, epoch: 4 | loss: 0.3807508
	speed: 0.1723s/iter; left time: 1219.6787s
	iters: 400, epoch: 4 | loss: 0.4984674
	speed: 0.1705s/iter; left time: 1189.8744s
	iters: 500, epoch: 4 | loss: 0.4244269
	speed: 0.1723s/iter; left time: 1185.5430s
	iters: 600, epoch: 4 | loss: 0.4717331
	speed: 0.1716s/iter; left time: 1163.2463s
	iters: 700, epoch: 4 | loss: 0.4011290
	speed: 0.1716s/iter; left time: 1145.8583s
	iters: 800, epoch: 4 | loss: 0.6557165
	speed: 0.1716s/iter; left time: 1129.0796s
	iters: 900, epoch: 4 | loss: 0.7772250
	speed: 0.1727s/iter; left time: 1119.1431s
	iters: 1000, epoch: 4 | loss: 0.3094614
	speed: 0.1737s/iter; left time: 1108.0418s
Epoch: 4 cost time: 183.43955302238464
Epoch: 4, Steps: 1054 | Train Loss: 0.5111327 Vali Loss: 0.3459088 Test Loss: 0.4894708
EarlyStopping counter: 3 out of 3
Early stopping
>>>>>>>testing : ETTm2_96_720_Autoformer_ETTm2_ftM_sl96_ll48_pl720_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
mse:0.46443870663642883, mae:0.4431818723678589
INFO: Trainable parameter count: 0.01M
INFO: Trainable parameter count: 0.01M
INFO: Trainable parameter count: 0.02M
INFO: Trainable parameter count: 0.03M
INFO: Trainable parameter count: 0.29M
INFO: Trainable parameter count: 0.29M
INFO: Trainable parameter count: 0.55M
INFO: Trainable parameter count: 0.55M
INFO: Trainable parameter count: 0.81M
INFO: Trainable parameter count: 0.81M
INFO: Trainable parameter count: 1.08M
INFO: Trainable parameter count: 1.08M
INFO: Trainable parameter count: 2.12M
INFO: Trainable parameter count: 3.17M
INFO: Trainable parameter count: 3.44M
INFO: Trainable parameter count: 3.44M
INFO: Trainable parameter count: 3.70M
INFO: Trainable parameter count: 3.70M
INFO: Trainable parameter count: 3.96M
INFO: Trainable parameter count: 3.96M
INFO: Trainable parameter count: 4.22M
INFO: Trainable parameter count: 4.22M
INFO: Trainable parameter count: 5.27M
INFO: Trainable parameter count: 6.32M
INFO: Trainable parameter count: 6.32M
INFO: Trainable parameter count: 6.32M
INFO: Trainable parameter count: 6.58M
INFO: Trainable parameter count: 6.58M
INFO: Trainable parameter count: 6.85M
INFO: Trainable parameter count: 6.85M
INFO: Trainable parameter count: 7.11M
INFO: Trainable parameter count: 7.11M
INFO: Trainable parameter count: 7.37M
INFO: Trainable parameter count: 7.37M
INFO: Trainable parameter count: 7.63M
INFO: Trainable parameter count: 7.64M
INFO: Trainable parameter count: 7.90M
INFO: Trainable parameter count: 7.90M
INFO: Trainable parameter count: 8.16M
INFO: Trainable parameter count: 8.16M
INFO: Trainable parameter count: 8.42M
INFO: Trainable parameter count: 8.42M
INFO: Trainable parameter count: 9.47M
INFO: Trainable parameter count: 10.52M
INFO: Trainable parameter count: 10.53M
INFO: Trainable parameter count: 10.53M
INFO: Trainable parameter count: 10.53M
INFO: Trainable parameter count: 10.54M
INFO: Trainable parameter count: 10.54M
